{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "prog_set = 'homework_4'\n",
    "\n",
    "# Sampling mode\n",
    "sampling_method = 'graph'\n",
    "\n",
    "# Inference method\n",
    "inference_method = 'VI'\n",
    "\n",
    "# Weights & biases\n",
    "use_wandb = False\n",
    "%env WANDB_NOTEBOOK_NAME='homework_4.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "if use_wandb: \n",
    "    wandb.init(project='test_homework4', entity='cs532-2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "def triangle_plots(dicts_of_samples, params, labels,\n",
    "    truths = None,\n",
    "    fig_size = 3.,\n",
    "    hist_bins = 'auto',\n",
    "    hist_density = True,\n",
    "    hist_alpha = 0.7,\n",
    "    scatter_alpha = 0.1,\n",
    "    scatter_size = 5.,\n",
    "    use_wandb = False, \n",
    "    wandb_name = None,\n",
    "    ):\n",
    "    '''\n",
    "    Makes a triangle plot\n",
    "    params:\n",
    "    dicts_of_samples: List of dictionaries of samples (e.g., dict['x'] = [1., 1.1, 1.3, ...])\n",
    "    params: List of names of parameters to plot (dictionary keys)\n",
    "    labels: List of axis labels corresponding to parameters\n",
    "    truths: List of true values of the parameters TODO: Option for None\n",
    "    '''\n",
    "    n = len(params)\n",
    "    fig, _ = plt.subplots(figsize=(n*fig_size, n*fig_size))\n",
    "    iplot = 0\n",
    "    samples = len(list(dicts_of_samples.values())[0][params[0]])\n",
    "    for ir, (param_r, label_r) in enumerate(zip(params, labels)):\n",
    "        for ic, (param_c, label_c) in enumerate(zip(params, labels)):\n",
    "            iplot += 1\n",
    "            if ir == ic:\n",
    "                plt.subplot(n, n, iplot)\n",
    "                if truths is not None:\n",
    "                    plt.axvline(truths[ir], color='black', ls='--', alpha=0.7, label='Truth')\n",
    "                for name, dict_of_samples in dicts_of_samples.items():\n",
    "                    label = name if (ir == 0) and (ic == 0) else None\n",
    "                    plt.hist(dict_of_samples[param_r], \n",
    "                        bins=hist_bins, density=hist_density, alpha=hist_alpha, label=label\n",
    "                    )\n",
    "                plt.xlabel(label_r) if ic==n-1 else plt.gca().set_xticklabels([])\n",
    "                plt.yticks([])\n",
    "                mean = dict_of_samples[param_r].mean(); std = dict_of_samples[param_r].std()\n",
    "                plt.axvline(mean, color='k', ls='--', label='Mean: %1.2f'%mean)\n",
    "                plt.axvline(mean-std, color='k', ls=':', label='Std: %1.2f'%std)\n",
    "                plt.axvline(mean+std, color='k', ls=':')\n",
    "                #if and iplot == 1: plt.legend(loc='upper left', bbox_to_anchor=(1., 1.))\n",
    "                plt.legend()\n",
    "            elif ir > ic:\n",
    "                plt.subplot(n, n, iplot)\n",
    "                if truths is not None:\n",
    "                    plt.plot([truths[ic]], [truths[ir]], color='black', marker='x', alpha=0.7, label='Truth')\n",
    "                for dict_of_samples in dicts_of_samples.values():\n",
    "                    plt.scatter(dict_of_samples[param_c], dict_of_samples[param_r], \n",
    "                            alpha=scatter_alpha, s=scatter_size,\n",
    "                    )\n",
    "                plt.xlabel(label_c) if ir==n-1 else plt.gca().set_xticklabels([])\n",
    "                plt.ylabel(label_r) if ic==0 else plt.gca().set_yticklabels([])\n",
    "    plt.suptitle('Samples: {:,}'.format(samples))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if use_wandb: wandb.log({wandb_name: wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def plot_traces(data_samples, data_resamples, nr, nc, names=None, panel_size=5., verbose=False, use_wandb=False, wandb_name=None):\n",
    "    samples = data_samples.shape[0]\n",
    "    #n = data_samples.shape[1]\n",
    "    n = nr*nc\n",
    "    fig, _ = plt.subplots(figsize=(nc*panel_size, nr*panel_size))\n",
    "    for i in range(n):\n",
    "        plt.subplot(nr, nc, 1+i)\n",
    "        mean = data_samples[:, i].mean()\n",
    "        std = data_samples[:, i].std()\n",
    "        if verbose:\n",
    "            print('Mean:', mean)\n",
    "            print('Std:', std)\n",
    "            plt.plot(data_resamples[:, i], color='C1', alpha=0.3)\n",
    "        plt.plot(data_samples[:, i], color='C0', alpha=0.3)\n",
    "        plt.scatter(list(range(samples)), data_samples[:, i], color='C0', marker='.', alpha=0.1, label='Unweighted')\n",
    "        plt.scatter(list(range(samples)), data_resamples[:, i], color='C1', marker='.', alpha=0.1, label='Resampled')\n",
    "        plt.axhline(mean, color='black', ls='--', label='Mean: %1.2f'%mean)\n",
    "        plt.axhline(mean-std, color='black', ls=':', label='Std: %1.2f'%std)\n",
    "        plt.axhline(mean+std, color='black', ls=':')\n",
    "        if names is not None: plt.ylabel(names[i])\n",
    "        leg = plt.legend()\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "        plt.xlabel('samples')\n",
    "        plt.xlim(left=0.)\n",
    "    plt.suptitle('Samples: {:,}'.format(samples))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if use_wandb: wandb.log({wandb_name: wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def plot_dist(data, nr, nc, names=None, panel_size=5., verbose=True, use_wandb=False, wandb_name=None):\n",
    "    samples = data.shape[0]\n",
    "    n = data.shape[1]\n",
    "    fig, _ = plt.subplots(figsize=(nc*panel_size, nr*panel_size))\n",
    "    for i in range(n):\n",
    "        plt.subplot(nr, nc, 1+i)\n",
    "        mean = data[:, i].mean()\n",
    "        std = data[:, i].std()\n",
    "        if verbose:\n",
    "            print('Mean:', mean)\n",
    "            print('Std:', std)\n",
    "        plt.hist(data[:, i], bins='auto', color='C%d'%i)\n",
    "        plt.axvline(mean, color='black', ls='--', label='Mean: %1.2f'%mean)\n",
    "        plt.axvline(mean-std, color='black', ls=':', label='Std: %1.2f'%std)\n",
    "        plt.axvline(mean+std, color='black', ls=':')\n",
    "        if names is not None: plt.xlabel(names[i])\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "    plt.suptitle('Samples: %d'%samples)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if use_wandb: wandb.log({wandb_name: wandb.Image(fig)})\n",
    "\n",
    "\n",
    "def plot_loss(data, ylim=None, log=False, **kwargs):\n",
    "    if log:\n",
    "        plt.semilogy(-data, **kwargs)\n",
    "    else:\n",
    "        plt.plot(data, **kwargs)\n",
    "    plt.xlabel('Step')\n",
    "    ylab = r'$-$ELBO' if log else 'ELBO'\n",
    "    plt.ylabel(ylab)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program 1\n",
    "variables = [r'$\\mu$']\n",
    "file_resamples = './../data/homework_4/1_%s_%s.dat'%(sampling_method, inference_method)\n",
    "file_samples = './../data/homework_4/1_%s_samples.dat'%(sampling_method)\n",
    "file_params = './../data/homework_4/1_%s_params.dat'%(sampling_method)\n",
    "file_loss = './../data/homework_4/1_%s_loss.dat'%(sampling_method)\n",
    "print('Files:', file_resamples, file_samples, file_params, file_loss)\n",
    "data_resamples, data_samples, data_loss = np.loadtxt(file_resamples), np.loadtxt(file_samples), np.loadtxt(file_loss)\n",
    "data_resamples, data_samples, data_loss = np.atleast_2d(data_resamples).T, np.atleast_2d(data_samples).T, np.atleast_2d(data_loss).T\n",
    "\n",
    "# Distribution parameters\n",
    "data_params = np.loadtxt(file_params)\n",
    "plt.title('Distribution parameters')\n",
    "plt.plot(data_params[:, 0], label='loc')\n",
    "plt.plot(data_params[:, 1], label='scale')\n",
    "plt.xlabel('Training step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plots\n",
    "print('Maximum loss:', max(data_loss))\n",
    "plot_loss(data_loss, color='k')\n",
    "samples_dicts = {'Unweighted': {'mu': data_samples[:, 0]}, 'Resampled': {'mu': data_resamples[:, 0]}}\n",
    "triangle_plots(samples_dicts, params=['mu'], labels=variables, fig_size=4., use_wandb=use_wandb, wandb_name='Program: 1')\n",
    "plot_traces(data_samples, data_resamples, nr=1, nc=data_resamples.shape[1], names=variables, use_wandb=use_wandb, wandb_name='Samples: 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program 2\n",
    "variables = ['slope', 'bias']\n",
    "file_resamples = './../data/homework_4/2_%s_%s.dat'%(sampling_method, inference_method)\n",
    "file_samples = './../data/homework_4/2_%s_samples.dat'%(sampling_method)\n",
    "file_loss = './../data/homework_4/2_%s_loss.dat'%(sampling_method)\n",
    "file_params = './../data/homework_4/2_%s_params.dat'%(sampling_method)\n",
    "print('Files:', file_resamples, file_samples, file_loss)\n",
    "data_resamples, data_samples, data_loss = np.loadtxt(file_resamples), np.loadtxt(file_samples), np.loadtxt(file_loss)\n",
    "\n",
    "# Distribution parameters\n",
    "data_params = np.loadtxt(file_params)\n",
    "plt.title('Distribution parameters')\n",
    "params = ['slope: loc', 'slope: scale', 'bias: loc', 'bias: scale']\n",
    "for i, param in enumerate(params):\n",
    "    plt.plot(data_params[:, i], label=param)\n",
    "plt.xlabel('Training step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plots\n",
    "print('Maximum loss:', max(data_loss))\n",
    "plot_loss(data_loss, color='k')\n",
    "samples_dicts = {\n",
    "    'Unweighted': {'slope': data_samples[:, 0], 'bias': data_samples[:, 1]}, \n",
    "    'Resamples': {'slope': data_resamples[:, 0], 'bias': data_resamples[:, 1]},\n",
    "    }\n",
    "triangle_plots(samples_dicts, params=variables, labels=variables, fig_size=3., use_wandb=use_wandb, wandb_name='Program: 2')\n",
    "plot_traces(data_samples, data_resamples, nr=1, nc=2, names=variables, use_wandb=use_wandb, wandb_name='Samples: 2')\n",
    "print('Covariance matrix:\\n', np.cov(data_resamples[:2, :2], bias=False, rowvar=False))\n",
    "\n",
    "# Posterior predictive\n",
    "plt.hist(data_resamples[:, 2], bins='auto', alpha=0.7, density=True)\n",
    "plt.title(r'Posterior predictive at $x = 10$')\n",
    "plt.ylabel('p(y|x=10)')\n",
    "plt.xlabel('y')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program 3\n",
    "\n",
    "# File\n",
    "variables = ['Are the points from the same cluster?']\n",
    "file = './../data/homework_4/3_%s_%s.dat'%(sampling_method, inference_method)\n",
    "file_loss = './../data/homework_4/3_%s_loss.dat'%(sampling_method)\n",
    "print('File:', file)\n",
    "\n",
    "# Load data\n",
    "data, data_loss = np.loadtxt(file), np.loadtxt(file_loss)\n",
    "data = np.atleast_2d(data).T\n",
    "samples_dict = {'Results': {'x': data[:, 0]}}\n",
    "\n",
    "# Plots\n",
    "plot_loss(data_loss, color='black', ylim=(-10000,3000))\n",
    "plot_loss(data_loss, log=True, color='black')#, ylim=(-300,300))\n",
    "triangle_plots(samples_dict, params=['x'], labels=variables, fig_size=5., use_wandb=use_wandb, wandb_name='Program: 3')\n",
    "print('Probability:', variables[0], data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program 4\n",
    "samples_file = './../data/homework_4/4_%s_samples.dat'%(sampling_method)\n",
    "resamples_file = './../data/homework_4/4_%s_%s.dat'%(sampling_method, inference_method)\n",
    "loss_file = './../data/homework_4/4_%s_loss.dat'%(sampling_method)\n",
    "\n",
    "# Loss\n",
    "loss_data = np.loadtxt(loss_file)\n",
    "plot_loss(loss_data, ylim=None, color='k')\n",
    "\n",
    "# Parameters\n",
    "num_params = 130\n",
    "num_bins = 100\n",
    "\n",
    "# Tensor heat maps\n",
    "for file in [samples_file, resamples_file]:\n",
    "\n",
    "    # Load data\n",
    "    print(file)\n",
    "    data = np.loadtxt(file)\n",
    "    print('Data shape:', data.shape)\n",
    "    print('First entry:', data[0, 0])\n",
    "\n",
    "    # Setup for heat maps\n",
    "    x = []; y = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(num_params):\n",
    "            x.append(j+0.5)\n",
    "            y.append(data[i, j])\n",
    "\n",
    "    # Plot heat maps\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.hist2d(x, y, bins=(num_params, num_bins), density=True, cmin=0., cmap='binary')\n",
    "    plt.xlabel('Position of tensor')\n",
    "    plt.xlim((0., num_params))\n",
    "    for val in [10, 110, 120]:\n",
    "        plt.axvline(val, color='black', ls='--')\n",
    "    plt.ylabel('Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# Posterior predictive\n",
    "plt.hist(data[:, num_params], density=True, alpha=0.7)\n",
    "plt.xlabel(r'Posterior predictive at $x=6$')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program 5\n",
    "variables = [r'$s$']\n",
    "file_resamples = './../data/homework_4/5_%s_%s.dat'%(sampling_method, inference_method)\n",
    "file_samples = './../data/homework_4/5_%s_samples.dat'%(sampling_method)\n",
    "file_loss = './../data/homework_4/5_%s_loss.dat'%(sampling_method)\n",
    "file_params = './../data/homework_4/5_%s_params.dat'%(sampling_method)\n",
    "\n",
    "# Loss\n",
    "data_loss = np.loadtxt(file_loss)\n",
    "print('Maximum loss:', max(data_loss))\n",
    "plot_loss(data_loss, color='black')\n",
    "plot_loss(data_loss, log=True, color='black')\n",
    "\n",
    "# Distribution parameters\n",
    "data_params = np.loadtxt(file_params)\n",
    "plt.title('Distribution parameters')\n",
    "params = ['loc', 'scale', 'conc', 'rate']\n",
    "for i, param in enumerate(params):\n",
    "    plt.plot(data_params[:, i], label=param)\n",
    "plt.xlabel('Training step')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution and traces\n",
    "print('Files:', file_resamples, file_samples)\n",
    "data_resamples, data_samples = np.loadtxt(file_resamples), np.loadtxt(file_samples)\n",
    "data_resamples, data_samples = np.atleast_2d(data_resamples).T, np.atleast_2d(data_samples).T\n",
    "print('Data shapes:', np.squeeze(data_resamples.shape), np.squeeze(data_samples.shape))\n",
    "samples_dict = {'Unweighted': {'s': data_samples[:, 0]}, 'Resampled:': {'s': data_resamples[:, 0]}}\n",
    "triangle_plots(samples_dict, params=['s'], labels=variables, fig_size=5., use_wandb=use_wandb, wandb_name='Program: 5')\n",
    "plot_traces(data_samples, data_resamples, nr=1, nc=data_resamples.shape[1], names=variables, use_wandb=use_wandb, wandb_name='Samples: 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish W&B\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
